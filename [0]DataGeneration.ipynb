{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[0]DataGeneration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "RzFl0wjy-RA3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IcXnyV2D-ruP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_data(k=2, d=1, k_useful=1, n_rows=1500, print_param=False):\n",
        "  \n",
        "  \"\"\"\n",
        "  generate data suitable for attention models with the dependency between parts of the image\n",
        "  \n",
        "  :parameters\n",
        "  k - number of parts in each data point\n",
        "  d - number of sub parts in each 'k' part\n",
        "  k_useful - number of parts with useful information [k_useful <= k]\n",
        "  n_rows - number of rows in the data set\n",
        "  print_param - boolean value to set the printinf status of parametrs\n",
        "  \"\"\"\n",
        "  data = []\n",
        "  \n",
        "  mean_useful = [0.]*d\n",
        "  std_dev_useful = np.eye(d)\n",
        "  mean_non_useful = [3.]*d\n",
        "  std_dev_non_useful = 2.*np.eye(d)\n",
        "  \n",
        "  is_useful_all = []\n",
        "  \n",
        "  for _ in range(n_rows):\n",
        "\n",
        "    # each element of 'is_useful' shows whether the corresponding part is useful or not\n",
        "    is_useful = np.array([0]*k)\n",
        "    useful_idx = np.random.choice(range(k), size=k_useful, replace=False)\n",
        "    for i in useful_idx:\n",
        "      is_useful[i] = 1\n",
        "    is_useful = [int(x) for x in is_useful]\n",
        "    is_useful_all.append(is_useful)\n",
        "\n",
        "    data_point = []\n",
        "    for i in range(k):\n",
        "      data_part = []\n",
        "      if is_useful[i] == 1:\n",
        "        data_part = np.matmul(np.random.randn(d_), std_dev_useful) + mean_useful\n",
        "      else:\n",
        "        data_part = np.matmul(np.random.randn(d_), std_dev_non_useful) + mean_non_useful\n",
        "      data_point.append(list(data_part))\n",
        "    \n",
        "    data.append(data_point)\n",
        "    \n",
        "  if print_param:\n",
        "    print(\"number of parts: \", k)\n",
        "    print(\"useful parts: \", is_useful_all[:5])\n",
        "    print(\"mean_non_useful: \", mean_useful)\n",
        "    print(\"std_dev_non_useful: \", std_dev_useful)\n",
        "    print(\"mean_non_useful: \", mean_non_useful)\n",
        "    print(\"std_dev_non_useful: \", std_dev_non_useful)\n",
        "    print(\"-\"*50)\n",
        "                             \n",
        "  data = np.array(data)\n",
        "  data = data.round(decimals=2)\n",
        "  \n",
        "  return data, is_useful_all, mean_useful, std_dev_useful, mean_non_useful, std_dev_non_useful "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8uZhQow1--bi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_y(x, is_useful_all):\n",
        "  \n",
        "  \"\"\"\n",
        "  find 'y' (class) based on the useful part\n",
        "  \n",
        "  :parameters\n",
        "  x - data features\n",
        "  is_useful_all - boolean nxk array\n",
        "  d - number of sub parts in each 'k' part of each data point\n",
        "  \"\"\"\n",
        "  x_useful = []\n",
        "  d = x.shape[2]\n",
        "  \n",
        "  for row, is_useful in zip(x, is_useful_all):\n",
        "    useful_sum = np.array([0.]*d)\n",
        "    for idx, value in enumerate(is_useful):\n",
        "      if value == 1:\n",
        "        useful_sum += row[idx]\n",
        "    x_useful.append(useful_sum)\n",
        "    \n",
        "  x_useful = np.array(x_useful)\n",
        "  w = np.random.uniform(low=-1, high=1, size=(d, 1))\n",
        "  \n",
        "  y = np.matmul(x_useful, w)\n",
        "  y = (y>0).astype(int)\n",
        "  \n",
        "  return y, w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IK5fJzru_CKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "cnt = 0\n",
        "\n",
        "k_d_list = [(2,1), (9,2), (9,32)] # list of tuples in (k, d) format\n",
        "\n",
        "for k_, d_ in k_d_list:\n",
        "  \n",
        "  n_ = max(k_*d_*3, 1500)\n",
        "  \n",
        "  data, is_useful_all, mean_useful, std_dev_useful, mean_non_useful, std_dev_non_useful = generate_data(k=k_, d=d_, n_rows=n_)\n",
        "  y , w = find_y(data, is_useful_all)\n",
        " \n",
        "  x_train, x_test, y_train, y_test, idx_train, idx_test = train_test_split(data, y, range(n_), test_size=0.33, random_state=100, stratify=y)\n",
        "  \n",
        "  class_count = {}\n",
        "  class_count['0'] = y.flatten().tolist().count(0)\n",
        "  class_count['1'] = y.flatten().tolist().count(1)\n",
        "  \n",
        "  each_data = {}\n",
        "  each_data['mean_useful'] = mean_useful\n",
        "  each_data['std_dev_useful'] = std_dev_useful.tolist()\n",
        "  each_data['mean_non_useful'] = mean_non_useful\n",
        "  each_data['std_dev_non_useful'] = std_dev_non_useful.tolist()\n",
        "  each_data['x_train'] = x_train.tolist()\n",
        "  each_data['x_test'] = x_test.tolist()\n",
        "  each_data['y_train'] = y_train.tolist()\n",
        "  each_data['y_test'] = y_test.tolist()\n",
        "  each_data['w'] = w.tolist()\n",
        "  each_data['class_count'] = class_count\n",
        "  each_data['is_useful_all'] = is_useful_all\n",
        "  each_data['idx_train'] = idx_train\n",
        "  each_data['idx_test'] =idx_test\n",
        "  all_data.append(each_data)\n",
        "  \n",
        "  cnt += 1\n",
        "  print(str(cnt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U82mbX4eAGJn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('data.json', 'w') as fp:\n",
        "    json.dump(all_data, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6t2e0bz6AZi6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('data.json')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}